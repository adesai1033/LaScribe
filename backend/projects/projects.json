[
  {
    "id": "817af407-6ac6-43c4-b6b0-adb4bbe855da",
    "name": "Hw2",
    "filename": "Hw2.pdf",
    "latex_code": "\\documentclass{article}\n\\usepackage{amsmath, amssymb, amsfonts}\n\\usepackage{geometry}\n\\geometry{margin=1in}\n\n\\begin{document}\n\n\\section*{Homework 2}\n\n\\textbf{1)} Given:\n\\begin{align}\nP(A) &= 0.3 \\\\\nP(B) &= 0.4 \\\\\nP(A \\cap B) &= 0.2\n\\end{align}\n\n\\textbf{a)} \n\\begin{align}\nP(A \\cup B) &= P(A) + P(B) - P(A \\cap B) \\\\\n&= 0.3 + 0.4 - 0.2 \\\\\n&= 0.5\n\\end{align}\n\n\\textbf{b)} If $A$ and $B$ are independent:\n\\begin{align}\nP(A) \\cdot P(B) &= P(A \\cap B) \\\\\n0.3 \\cdot 0.4 &= 0.12 \\neq 0.2\n\\end{align}\nTherefore, $A$ and $B$ are not independent.\n\n\\textbf{c)} \n\\begin{align}\nP(A^c \\cap B) &= P(B) - P(A \\cap B) \\\\\n&= 0.4 - 0.2 \\\\\n&= 0.2\n\\end{align}\n\n\\textbf{2)} Given: $f_X(x) = \\begin{cases} 2x & 0 \\leq x \\leq 1 \\\\ 0 & \\text{otherwise} \\end{cases}$\n\n\\textbf{a)} \n\\begin{align}\nE(X) &= \\int_{-\\infty}^{\\infty} x f(x) \\, dx \\\\\n&= \\int_0^1 x \\cdot 2x \\, dx \\\\\n&= \\int_0^1 2x^2 \\, dx \\\\\n&= \\frac{2x^3}{3} \\Big|_0^1 \\\\\n&= \\frac{2}{3}\n\\end{align}\n\n\\begin{align}\n\\text{Var}(X) &= E(X^2) - [E(X)]^2 \\\\\nE(X^2) &= \\int_{-\\infty}^{\\infty} x^2 f(x) \\, dx \\\\\n&= \\int_0^1 x^2 \\cdot 2x \\, dx \\\\\n&= \\int_0^1 2x^3 \\, dx \\\\\n&= \\frac{2x^4}{4} \\Big|_0^1 \\\\\n&= \\frac{1}{2}\n\\end{align}\n\n\\begin{align}\n\\text{Var}(X) &= \\frac{1}{2} - \\left(\\frac{2}{3}\\right)^2 \\\\\n&= \\frac{1}{2} - \\frac{4}{9} \\\\\n&= \\frac{1}{18}\n\\end{align}\n\n\\textbf{b)} For a Bernoulli distribution: $P(X = x) = p^x(1-p)^{1-x}$\n\n\\begin{align}\nP(X = 1) &= p^1(1-p)^0 = p \\\\\nP(X = 0) &= p^0(1-p)^1 = (1-p)\n\\end{align}\n\n\\begin{align}\nE(X) &= \\sum x P(X = x) \\\\\n&= 0(1-p) + 1(p) \\\\\n&= p\n\\end{align}\n\n\\begin{align}\nE(X^2) &= \\sum x^2 P(X = x) \\\\\n&= 0^2(1-p) + 1^2(p) \\\\\n&= p\n\\end{align}\n\n\\begin{align}\n\\text{Var}(X) &= E(X^2) - [E(X)]^2 \\\\\n&= p - p^2 \\\\\n&= p(1-p)\n\\end{align}\n\n\\newpage\n\n\\textbf{3)} Given: $f_{X,Y}(x,y) = 6xy$ for $0 \\leq x \\leq 1, 0 \\leq y \\leq 1$\n\n\\textbf{a)} \n\\begin{align}\nf_X(x) &= \\int_0^1 6xy \\, dy \\\\\n&= 6x \\int_0^1 y \\, dy \\\\\n&= 6x \\cdot \\frac{y^2}{2} \\Big|_0^1 \\\\\n&= 6x \\cdot \\frac{1}{2} \\\\\n&= 3x\n\\end{align}\n\nSimilarly, $f_Y(y) = 3y$\n\n\\textbf{b)} \n\\begin{align}\nf_X(x) \\cdot f_Y(y) &= 3x \\cdot 3y = 9xy \\neq 6xy = f_{X,Y}(x,y)\n\\end{align}\nTherefore, $X$ and $Y$ are not independent.\n\n\\textbf{4)} Event $A$: sum is 5 or 6, so $P(A) = \\frac{9}{36} = \\frac{1}{4}$\n\nEvent $B$: outcomes $(3,6), (6,6), (3,6), (6,6), (6,3), (3,4), (6,3), (5,4), (4,5), (2,4)$\n$P(B) = \\frac{10}{36}$\n\n\\begin{align}\n|A \\cap B| &= |(5,4), (5,5), (5,6), (6,3), (6,4), (6,5), (4,6)| = 7 \\\\\nP(B|A) &= \\frac{P(A \\cap B)}{P(A)} = \\frac{7/36}{1/4} = \\frac{7/36}{9/36} = \\frac{7}{9}\n\\end{align}\n\n\\textbf{5)} Given: $f(x) = 3(1-x)^2$ and $Y = (1-X)^{1/3}$\n\nFrom $Y^{1/3} = 1-X$, we get $X = 1-Y^{1/3}$\n\n\\begin{align}\n\\frac{dx}{dy} &= -\\frac{1}{3}Y^{-2/3}\n\\end{align}\n\n\\begin{align}\nf_Y(y) &= f_X(1-y^{1/3}) \\left|\\frac{dx}{dy}\\right| \\\\\n&= 3(1-(1-y^{1/3}))^2 \\cdot \\frac{1}{3}y^{-2/3} \\\\\n&= 3(y^{1/3})^2 \\cdot \\frac{1}{3}y^{-2/3} \\\\\n&= 1\n\\end{align}\n\nTherefore, $f_Y(y) = 1$ for $0 \\leq y \\leq 1$, and 0 otherwise.\n\n\\textbf{6)} For $\\text{Cov}\\left(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n a_j X_j\\right)$:\n\nLet $Y = \\sum_{i=1}^n a_i X_i$ and $Z = \\sum_{j=1}^n a_j X_j$\n\n\\begin{align}\nE(Y) &= E\\left(\\sum_{i=1}^n a_i X_i\\right) = \\sum_{i=1}^n a_i E(X_i) \\\\\nE(Z) &= \\sum_{j=1}^n a_j E(X_j)\n\\end{align}\n\n\\begin{align}\nE(YZ) &= E\\left(\\sum_{i=1}^n a_i X_i \\sum_{j=1}^n a_j X_j\\right) \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j E(X_i X_j)\n\\end{align}\n\n\\begin{align}\n\\text{Cov}(Y,Z) &= E(YZ) - E(Y)E(Z) \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j E(X_i X_j) - \\sum_{i=1}^n a_i E(X_i) \\sum_{j=1}^n a_j E(X_j) \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j [E(X_i X_j) - E(X_i)E(X_j)] \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j \\text{Cov}(X_i, X_j)\n\\end{align}\n\nSince $a^T \\Sigma a = \\sum_{i=1}^n \\sum_{j=1}^n a_i \\Sigma_{ij} a_j = \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j \\text{Cov}(X_i, X_j)$\n\n\\newpage\n\n\\textbf{7)} Given: $f(x) = \\log(1 + e^x)$ and $\\sigma(x) = \\frac{e^x}{1 + e^x}$\n\n\\textbf{(1)} \n\\begin{align}\n\\frac{d f(x)}{dx} &= \\frac{1}{1 + e^x} \\cdot e^x = \\frac{e^x}{1 + e^x} = \\sigma(x)\n\\end{align}\n\n\\textbf{(2)} \n\\begin{align}\n\\frac{d \\sigma(x)}{dx} &= \\frac{d}{dx}\\left(\\frac{e^x}{1 + e^x}\\right) \\\\\n&= \\frac{e^x(1 + e^x) - e^x \\cdot e^x}{(1 + e^x)^2} \\\\\n&= \\frac{e^x + e^{2x} - e^{2x}}{(1 + e^x)^2} \\\\\n&= \\frac{e^x}{(1 + e^x)^2} \\\\\n&= \\frac{e^x}{1 + e^x} \\cdot \\frac{1}{1 + e^x} \\\\\n&= \\sigma(x)(1 - \\sigma(x))\n\\end{align}\n\n\\textbf{(3)} \n\\begin{align}\n\\log(\\sigma(x)) &= \\log\\left(\\frac{e^x}{1 + e^x}\\right) \\\\\n&= \\log(e^x) - \\log(1 + e^x) \\\\\n&= x - f(x) \\\\\n&= -f(-x)\n\\end{align}\n\n\\textbf{(4)} \n\\begin{align}\n1 - \\sigma(x) &= 1 - \\frac{e^x}{1 + e^x} \\\\\n&= \\frac{1 + e^x - e^x}{1 + e^x} \\\\\n&= \\frac{1}{1 + e^x} \\\\\n&= \\frac{e^{-x}}{e^{-x}(1 + e^x)} \\\\\n&= \\frac{e^{-x}}{e^{-x} + 1} \\\\\n&= \\sigma(-x)\n\\end{align}\n\n\\textbf{(5)} \n\\begin{align}\n\\sigma^{-1}(x) &= \\log\\left(\\frac{x}{1-x}\\right)\n\\end{align}\n\nLet $y = \\sigma(x) = \\frac{e^x}{1 + e^x}$\n\nThen $y(1 + e^x) = e^x$, so $y + ye^x = e^x$, which gives $y = e^x(1-y)$\n\nTherefore $e^x = \\frac{y}{1-y}$, and $x = \\log\\left(\\frac{y}{1-y}\\right)$\n\n\\textbf{(6)} For $x > 0$, $f^{-1}(x) = \\log(e^x - 1)$\n\nLet $y = \\log(1 + e^x)$, then $e^y = 1 + e^x$, so $e^x = e^y - 1$\n\nTherefore $x = \\log(e^y - 1)$\n\n\\textbf{(7)} \n\\begin{align}\nf(x) &= \\int_{-\\infty}^x \\sigma(y) \\, dy \\\\\n&= \\int_{-\\infty}^x \\frac{e^y}{1 + e^y} \\, dy\n\\end{align}\n\nLet $u = 1 + e^y$, then $du = e^y dy$\n\n\\begin{align}\n\\int \\frac{e^y}{1 + e^y} \\, dy &= \\int \\frac{1}{u} \\, du = \\ln u = \\ln(1 + e^y)\n\\end{align}\n\n\\begin{align}\nf(x) &= \\ln(1 + e^x) \\Big|_{-\\infty}^x \\\\\n&= \\ln(1 + e^x) - \\ln(1 + e^{-\\infty}) \\\\\n&= \\ln(1 + e^x) - \\ln(1) \\\\\n&= \\ln(1 + e^x)\n\\end{align}\n\n\\textbf{(8)} \n\\begin{align}\nf(x) - f(-x) &= \\log(1 + e^x) - \\log(1 + e^{-x}) \\\\\n&= \\log(1 + e^x) - \\log\\left(\\frac{e^x + 1}{e^x}\\right) \\\\\n&= \\log(1 + e^x) - [\\log(e^x + 1) - x] \\\\\n&= x\n\\end{align}\n\n\\end{document}",
    "created_at": "2025-07-09T19:55:46.086036",
    "updated_at": "2025-07-09T19:55:46.086062"
  },
  {
    "id": "29030434-76f9-4a4d-b6dd-88d90f36812d",
    "name": "Hw2",
    "filename": "Hw2.pdf",
    "latex_code": "\\documentclass{article}\n\\usepackage{amsmath, amssymb, amsfonts}\n\\usepackage{geometry}\n\\geometry{margin=1in}\n\n\\begin{document}\n\n\\section*{Homework 2}\n\n\\textbf{1)} Given:\n\\begin{align}\nP(A) &= 0.3 \\\\\nP(B) &= 0.4 \\\\\nP(A \\cap B) &= 0.2\n\\end{align}\n\n\\textbf{a)} \n\\begin{align}\nP(A \\cup B) &= P(A) + P(B) - P(A \\cap B) \\\\\n&= 0.3 + 0.4 - 0.2 \\\\\n&= 0.5\n\\end{align}\n\n\\textbf{b)} If $A$ and $B$ are independent:\n\\begin{align}\nP(A) \\cdot P(B) &= P(A \\cap B) \\\\\n0.3 \\cdot 0.4 &= 0.12 \\neq 0.2\n\\end{align}\nTherefore, $A$ and $B$ are not independent.\n\n\\textbf{c)} \n\\begin{align}\nP(A^c \\cap B) &= P(B) - P(A \\cap B) \\\\\n&= 0.4 - 0.2 \\\\\n&= 0.2\n\\end{align}\n\n\\textbf{2)} Given: $f_X(x) = \\begin{cases} 2x & 0 \\leq x \\leq 1 \\\\ 0 & \\text{otherwise} \\end{cases}$\n\n\\textbf{a)} \n\\begin{align}\nE(X) &= \\int_{-\\infty}^{\\infty} x f(x) dx \\\\\n&= \\int_0^1 x \\cdot 2x dx \\\\\n&= \\int_0^1 2x^2 dx \\\\\n&= \\frac{2x^3}{3}\\Big|_0^1 \\\\\n&= \\frac{2}{3}\n\\end{align}\n\n\\begin{align}\n\\text{Var}(X) &= E(X^2) - [E(X)]^2 \\\\\nE(X^2) &= \\int_{-\\infty}^{\\infty} x^2 f(x) dx \\\\\n&= \\int_0^1 x^2 \\cdot 2x dx \\\\\n&= \\int_0^1 2x^3 dx \\\\\n&= \\frac{2x^4}{4}\\Big|_0^1 \\\\\n&= \\frac{1}{2}\n\\end{align}\n\n\\begin{align}\n\\text{Var}(X) &= \\frac{1}{2} - \\left(\\frac{2}{3}\\right)^2 \\\\\n&= \\frac{1}{2} - \\frac{4}{9} \\\\\n&= \\frac{9-8}{18} \\\\\n&= \\frac{1}{18}\n\\end{align}\n\n\\textbf{b)} For Bernoulli distribution: $P(X = x) = p^x(1-p)^{1-x}$\n\n\\begin{align}\nP(X = 1) &= p^1(1-p)^0 = p \\\\\nP(X = 0) &= p^0(1-p)^1 = (1-p)\n\\end{align}\n\n\\begin{align}\nE(X) &= \\sum x P(X = x) \\\\\n&= 0(1-p) + 1(p) \\\\\n&= p\n\\end{align}\n\n\\begin{align}\nE(X^2) &= \\sum x^2 P(X = x) \\\\\n&= 0^2(1-p) + 1^2(p) \\\\\n&= p\n\\end{align}\n\n\\begin{align}\n\\text{Var}(X) &= E(X^2) - [E(X)]^2 \\\\\n&= p - p^2 \\\\\n&= p(1-p)\n\\end{align}\n\n\\newpage\n\n\\textbf{3)} Given: $f_{X,Y}(x,y) = 6xy$ for $0 \\leq x \\leq 1, 0 \\leq y \\leq 1$\n\n\\textbf{a)} \n\\begin{align}\nf_X(x) &= \\int_0^1 6xy dy \\\\\n&= 6x \\left[\\frac{y^2}{2}\\right]_0^1 \\\\\n&= 6x \\cdot \\frac{1}{2} \\\\\n&= 3x\n\\end{align}\n\nSimilarly:\n\\begin{align}\nf_Y(y) = 3y\n\\end{align}\n\n\\textbf{b)} \n\\begin{align}\nf_X(x) \\cdot f_Y(y) &= 3x \\cdot 3y = 9xy \\neq 6xy = f_{X,Y}(x,y)\n\\end{align}\nTherefore, $X$ and $Y$ are not independent.\n\n\\textbf{4)} Event $A$: sum is 5 or 6, so $P(A) = \\frac{9}{36} = \\frac{1}{4}$\n\nEvent $B$: at least one die shows 3, 4, 5, or 6\n\\begin{align}\n|B| &= \\{(3,6), (6,6), (3,6), (6,6), (6,3), (3,4), (6,3), (5,4), (4,5), (5,5)\\} \\\\\nP(B) &= \\frac{27}{36} = \\frac{3}{4}\n\\end{align}\n\n\\begin{align}\n|A \\cap B| &= \\{(3,3), (5,5), (5,6), (6,3), (6,5), (6,5)\\} \\\\\n&= 7 \\text{ outcomes} \\\\\nP(A \\cap B) &= \\frac{7}{36}\n\\end{align}\n\n\\begin{align}\nP(B|A) &= \\frac{P(A \\cap B)}{P(A)} \\\\\n&= \\frac{7/36}{1/4} \\\\\n&= \\frac{7}{36} \\cdot \\frac{4}{1} \\\\\n&= \\frac{7}{9}\n\\end{align}\n\n\\textbf{5)} Given: $f(x) = 3(1-x)^2$ and $Y = (1-X)^{1/3}$\n\nFrom $Y = (1-X)^{1/3}$:\n\\begin{align}\nY^{1/3} &= 1-X \\\\\nX &= 1-Y^{1/3}\n\\end{align}\n\n\\begin{align}\n\\frac{dx}{dy} &= -\\frac{1}{3}Y^{-2/3}\n\\end{align}\n\n\\begin{align}\nf_Y(y) &= f_X(1-y^{1/3}) \\left|\\frac{dx}{dy}\\right| \\\\\n&= 3(1-(1-y^{1/3}))^2 \\cdot \\frac{1}{3}y^{-2/3} \\\\\n&= 3(y^{1/3})^2 \\cdot \\frac{1}{3}y^{-2/3} \\\\\n&= 1\n\\end{align}\n\nTherefore: $f_Y(y) = \\begin{cases} 1 & 0 \\leq y \\leq 1 \\\\ 0 & \\text{otherwise} \\end{cases}$\n\n\\textbf{6)} For $\\text{Cov}\\left(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n a_j X_j\\right)$:\n\nLet $Y = \\sum_{i=1}^n a_i X_i$ and $Z = \\sum_{j=1}^n a_j X_j$\n\n\\begin{align}\nE(Y) &= E\\left(\\sum_{i=1}^n a_i X_i\\right) = \\sum_{i=1}^n a_i E(X_i) \\\\\nE(Z) &= \\sum_{j=1}^n a_j E(X_j)\n\\end{align}\n\n\\begin{align}\nE(YZ) &= E\\left(\\sum_{i=1}^n a_i X_i \\sum_{j=1}^n a_j X_j\\right) \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j E(X_i X_j)\n\\end{align}\n\n\\begin{align}\n\\text{Cov}(Y,Z) &= E(YZ) - E(Y)E(Z) \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j E(X_i X_j) - \\sum_{i=1}^n a_i E(X_i) \\sum_{j=1}^n a_j E(X_j) \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j [E(X_i X_j) - E(X_i)E(X_j)] \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j \\text{Cov}(X_i, X_j)\n\\end{align}\n\nSince $a^T \\Sigma a = \\sum_{i=1}^n \\sum_{j=1}^n a_i \\sigma_{ij} a_j = \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j \\text{Cov}(X_i, X_j)$\n\n\\newpage\n\n\\textbf{7)} Given: $f(x) = \\log(1 + e^x)$ and $\\sigma(x) = \\frac{e^x}{1 + e^x}$\n\n\\textbf{(1)} \n\\begin{align}\n\\frac{d f(x)}{dx} &= \\frac{1}{1 + e^x} \\cdot \\frac{d}{dx}(1 + e^x) \\\\\n&= \\frac{1}{1 + e^x} \\cdot e^x \\\\\n&= \\frac{e^x}{1 + e^x} \\\\\n&= \\sigma(x)\n\\end{align}\n\n\\textbf{(2)} \n\\begin{align}\n\\frac{d \\sigma(x)}{dx} &= \\frac{d}{dx}\\left(\\frac{e^x}{1 + e^x}\\right) \\\\\n&= \\frac{e^x(1 + e^x) - e^x \\cdot e^x}{(1 + e^x)^2} \\\\\n&= \\frac{e^x + e^{2x} - e^{2x}}{(1 + e^x)^2} \\\\\n&= \\frac{e^x}{(1 + e^x)^2} \\\\\n&= \\sigma(x) \\cdot \\frac{1}{1 + e^x} \\\\\n&= \\sigma(x)(1 - \\sigma(x))\n\\end{align}\n\n\\textbf{(3)} \n\\begin{align}\n\\log(\\sigma(x)) &= \\log\\left(\\frac{e^x}{1 + e^x}\\right) \\\\\n&= \\log(e^x) - \\log(1 + e^x) \\\\\n&= x - f(x)\n\\end{align}\n\n\\textbf{(4)} \n\\begin{align}\n1 - \\sigma(x) &= 1 - \\frac{e^x}{1 + e^x} \\\\\n&= \\frac{1 + e^x - e^x}{1 + e^x} \\\\\n&= \\frac{1}{1 + e^x}\n\\end{align}\n\nTherefore: $\\sigma(-x) = \\frac{e^{-x}}{1 + e^{-x}} = \\frac{1}{e^x + 1} = 1 - \\sigma(x)$\n\n\\textbf{(5)} \n\\begin{align}\n\\sigma^{-1}(x) &= \\log\\left(\\frac{x}{1-x}\\right)\n\\end{align}\n\nLet $y = \\sigma(x) = \\frac{e^x}{1 + e^x}$\n\nThen: $y(1 + e^x) = e^x$, so $y + ye^x = e^x$, which gives $y = e^x(1-y)$\n\nTherefore: $e^x = \\frac{y}{1-y}$, so $x = \\log\\left(\\frac{y}{1-y}\\right)$\n\n\\textbf{(6)} For $x > 0$:\n\\begin{align}\nf^{-1}(x) &= \\log(e^x - 1)\n\\end{align}\n\nLet $y = f(x) = \\log(1 + e^x)$\n\nThen: $e^y = 1 + e^x$, so $e^x = e^y - 1$\n\nTherefore: $x = \\log(e^y - 1)$\n\n\\textbf{(7)} \n\\begin{align}\nf(x) &= \\int_{-\\infty}^x \\sigma(y) dy \\\\\n&= \\int_{-\\infty}^x \\frac{e^y}{1 + e^y} dy\n\\end{align}\n\nLet $u = 1 + e^y$, then $du = e^y dy$:\n\\begin{align}\n\\int \\frac{e^y}{1 + e^y} dy &= \\int \\frac{1}{u} du \\\\\n&= \\ln(u) + C \\\\\n&= \\ln(1 + e^y) + C\n\\end{align}\n\n\\begin{align}\nf(x) &= \\ln(1 + e^x) - \\lim_{y \\to -\\infty} \\ln(1 + e^y) \\\\\n&= \\ln(1 + e^x) - \\ln(1) \\\\\n&= \\ln(1 + e^x)\n\\end{align}\n\n\\textbf{(8)} \n\\begin{align}\nf(x) - f(-x) &= \\log(1 + e^x) - \\log(1 + e^{-x}) \\\\\n&= \\log(1 + e^x) - \\log\\left(\\frac{e^x + 1}{e^x}\\right) \\\\\n&= \\log(1 + e^x) - [\\log(e^x + 1) - x] \\\\\n&= x\n\\end{align}\n\n\\end{document}",
    "created_at": "2025-07-09T22:09:08.632803",
    "updated_at": "2025-07-09T22:09:08.632813"
  },
  {
    "id": "1fa16898-2016-41fc-a632-92b2e66c6193",
    "name": "Hw2",
    "filename": "Hw2.pdf",
    "latex_code": "\\documentclass{article}\n\\usepackage{amsmath, amssymb, amsfonts}\n\\usepackage{geometry}\n\\geometry{margin=1in}\n\n\\begin{document}\n\n\\section*{Homework 2}\n\n\\textbf{1)} Given:\n\\begin{align}\nP(A) &= 0.3 \\\\\nP(B) &= 0.4 \\\\\nP(A \\cap B) &= 0.2\n\\end{align}\n\n\\textbf{a)} \n\\begin{align}\nP(A \\cup B) &= P(A) + P(B) - P(A \\cap B) \\\\\n&= 0.3 + 0.4 - 0.2 \\\\\n&= 0.5\n\\end{align}\n\n\\textbf{b)} If $A$ and $B$ are independent:\n\\begin{align}\nP(A) \\cdot P(B) &= P(A \\cap B) \\\\\n0.3 \\cdot 0.4 &= 0.12 \\neq 0.2\n\\end{align}\nTherefore, $A$ and $B$ are not independent.\n\n\\textbf{c)} \n\\begin{align}\nP(A^c \\cap B) &= P(B) - P(A \\cap B) \\\\\n&= 0.4 - 0.2 \\\\\n&= 0.2\n\\end{align}\n\n\\textbf{2)} Given: $f_X(x) = \\begin{cases} 2x & 0 \\leq x \\leq 1 \\\\ 0 & \\text{otherwise} \\end{cases}$\n\n\\textbf{a)} \n\\begin{align}\nE(X) &= \\int_{-\\infty}^{\\infty} x f(x) dx \\\\\n&= \\int_0^1 x \\cdot 2x dx \\\\\n&= \\int_0^1 2x^2 dx \\\\\n&= \\frac{2x^3}{3}\\Big|_0^1 \\\\\n&= \\frac{2}{3}\n\\end{align}\n\n\\begin{align}\n\\text{Var}(X) &= E(X^2) - [E(X)]^2 \\\\\nE(X^2) &= \\int_{-\\infty}^{\\infty} x^2 f(x) dx \\\\\n&= \\int_0^1 x^2 \\cdot 2x dx \\\\\n&= \\int_0^1 2x^3 dx \\\\\n&= \\frac{2x^4}{4}\\Big|_0^1 \\\\\n&= \\frac{1}{2}\n\\end{align}\n\n\\begin{align}\n\\text{Var}(X) &= \\frac{1}{2} - \\left(\\frac{2}{3}\\right)^2 \\\\\n&= \\frac{1}{2} - \\frac{4}{9} \\\\\n&= \\frac{9-8}{18} \\\\\n&= \\frac{1}{18}\n\\end{align}\n\n\\textbf{b)} For Bernoulli distribution: $P(X = x) = p^x(1-p)^{1-x}$\n\n\\begin{align}\nP(X = 1) &= p^1(1-p)^0 = p \\\\\nP(X = 0) &= p^0(1-p)^1 = (1-p)\n\\end{align}\n\n\\begin{align}\nE(X) &= \\sum x P(X = x) \\\\\n&= 0(1-p) + 1(p) \\\\\n&= p\n\\end{align}\n\n\\begin{align}\nE(X^2) &= \\sum x^2 P(X = x) \\\\\n&= 0^2(1-p) + 1^2(p) \\\\\n&= p\n\\end{align}\n\n\\begin{align}\n\\text{Var}(X) &= E(X^2) - [E(X)]^2 \\\\\n&= p - p^2 \\\\\n&= p(1-p)\n\\end{align}\n\n\\newpage\n\n\\textbf{3)} Given: $f_{X,Y}(x,y) = 6xy$ for $0 \\leq x \\leq 1, 0 \\leq y \\leq 1$\n\n\\textbf{a)} \n\\begin{align}\nf_X(x) &= \\int_0^1 6xy dy \\\\\n&= 6x \\left[\\frac{y^2}{2}\\right]_0^1 \\\\\n&= 6x \\cdot \\frac{1}{2} \\\\\n&= 3x\n\\end{align}\n\nSimilarly:\n\\begin{align}\nf_Y(y) = 3y\n\\end{align}\n\n\\textbf{b)} \n\\begin{align}\nf_X(x) \\cdot f_Y(y) &= 3x \\cdot 3y = 9xy \\neq 6xy = f_{X,Y}(x,y)\n\\end{align}\nTherefore, $X$ and $Y$ are not independent.\n\n\\textbf{4)} Event $A$: sum is 5 or 6, so $P(A) = \\frac{9}{36} = \\frac{1}{4}$\n\nEvent $B$: at least one die shows 3, 4, 5, or 6\n\\begin{align}\n|B| &= \\{(3,6), (4,6), (5,6), (6,6), (6,3), (6,4), (6,5), (3,4), (4,3), (5,4), (4,5)\\} \\\\\nP(B) &= \\frac{10}{36}\n\\end{align}\n\n\\begin{align}\nP(B|A) &= \\frac{P(A \\cap B)}{P(A)}\n\\end{align}\n\n\\begin{align}\n|A \\cap B| &= \\{(5,4), (5,5), (5,6), (6,3), (6,4), (6,5), (4,5)\\} \\\\\n&= 7\n\\end{align}\n\n\\begin{align}\nP(B|A) &= \\frac{7/36}{1/4} = \\frac{7/36}{9/36} = \\frac{7}{9}\n\\end{align}\n\n\\textbf{5)} Given: $f(x) = 3(1-x)^2$ for $0 \\leq x \\leq 1$\n\nLet $Y = (1-X)^{1/3}$, so $Y^{1/3} = 1-X$, which gives $X = 1-Y^{1/3}$\n\n\\begin{align}\n\\frac{dx}{dy} &= -\\frac{1}{3}Y^{-2/3}\n\\end{align}\n\n\\begin{align}\nf_Y(y) &= f_X(1-y^{1/3}) \\left|\\frac{dx}{dy}\\right| \\\\\n&= 3(1-(1-y^{1/3}))^2 \\cdot \\frac{1}{3}y^{-2/3} \\\\\n&= 3(y^{1/3})^2 \\cdot \\frac{1}{3}y^{-2/3} \\\\\n&= 1\n\\end{align}\n\nTherefore: $f_Y(y) = \\begin{cases} 1 & 0 \\leq y \\leq 1 \\\\ 0 & \\text{otherwise} \\end{cases}$\n\n\\textbf{6)} \n\\begin{align}\n\\text{Cov}\\left(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n a_j X_j\\right) &= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j \\text{Cov}(X_i, X_j) \\\\\n&= a^T \\Sigma a\n\\end{align}\n\nwhere $Y = \\sum_{i=1}^n a_i X_i$ and $Z = \\sum_{j=1}^n a_j X_j$\n\n\\begin{align}\nE(Y) &= E\\left(\\sum_{i=1}^n a_i X_i\\right) = \\sum_{i=1}^n a_i E(X_i) \\\\\nE(Z) &= \\sum_{j=1}^n a_j E(X_j)\n\\end{align}\n\n\\begin{align}\n\\text{Cov}(Y,Z) &= E(YZ) - E(Y)E(Z) \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j E(X_i X_j) - \\sum_{i=1}^n a_i E(X_i) \\sum_{j=1}^n a_j E(X_j) \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j [E(X_i X_j) - E(X_i)E(X_j)] \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j \\text{Cov}(X_i, X_j)\n\\end{align}\n\n\\newpage\n\n\\textbf{7)} Given: $f(x) = \\log(1 + e^x)$ and $\\sigma(x) = \\frac{e^x}{1 + e^x}$\n\n\\textbf{(1)} \n\\begin{align}\n\\frac{d f(x)}{dx} &= \\frac{1}{1 + e^x} \\cdot \\frac{d}{dx}(1 + e^x) \\\\\n&= \\frac{e^x}{1 + e^x} \\\\\n&= \\sigma(x)\n\\end{align}\n\n\\textbf{(2)} \n\\begin{align}\n\\frac{d \\sigma(x)}{dx} &= \\frac{d}{dx}\\left(\\frac{e^x}{1 + e^x}\\right) \\\\\n&= \\frac{e^x(1 + e^x) - e^x \\cdot e^x}{(1 + e^x)^2} \\\\\n&= \\frac{e^x(1 + e^x - e^x)}{(1 + e^x)^2} \\\\\n&= \\frac{e^x}{(1 + e^x)^2} \\\\\n&= \\sigma(x) \\cdot \\frac{1}{1 + e^x} \\\\\n&= \\sigma(x)(1 - \\sigma(x))\n\\end{align}\n\n\\textbf{(3)} \n\\begin{align}\n\\log(\\sigma(x)) &= \\log\\left(\\frac{e^x}{1 + e^x}\\right) \\\\\n&= \\log(e^x) - \\log(1 + e^x) \\\\\n&= x - f(x) \\\\\n&= -f(-x)\n\\end{align}\n\n\\textbf{(4)} \n\\begin{align}\n1 - \\sigma(x) &= 1 - \\frac{e^x}{1 + e^x} \\\\\n&= \\frac{1 + e^x - e^x}{1 + e^x} \\\\\n&= \\frac{1}{1 + e^x} \\\\\n&= \\frac{e^{-x}}{e^{-x}(1 + e^x)} \\\\\n&= \\frac{e^{-x}}{e^{-x} + 1} \\\\\n&= \\sigma(-x)\n\\end{align}\n\n\\textbf{(5)} \n\\begin{align}\n\\sigma^{-1}(x) &= \\log\\left(\\frac{x}{1-x}\\right)\n\\end{align}\n\nLet $y = \\sigma(x) = \\frac{e^x}{1 + e^x}$\n\nThen: $y(1 + e^x) = e^x$, so $y + ye^x = e^x$, which gives $y = e^x(1-y)$\n\nTherefore: $e^x = \\frac{y}{1-y}$, and $x = \\log\\left(\\frac{y}{1-y}\\right)$\n\n\\textbf{(6)} For $x > 0$:\n\\begin{align}\nf^{-1}(x) &= \\log(e^x - 1)\n\\end{align}\n\nLet $y = \\log(1 + e^x)$. Then $e^y = 1 + e^x$, so $e^x = e^y - 1$, and $x = \\log(e^y - 1)$.\n\n\\textbf{(7)} \n\\begin{align}\nf(x) &= \\int_{-\\infty}^x \\sigma(y) dy \\\\\n&= \\int_{-\\infty}^x \\frac{e^y}{1 + e^y} dy\n\\end{align}\n\nLet $u = 1 + e^y$, then $du = e^y dy$:\n\\begin{align}\n\\int \\frac{1}{u} du &= \\ln(1 + e^y)\\Big|_{-\\infty}^x \\\\\n&= \\ln(1 + e^x) - \\ln(1 + e^{-\\infty}) \\\\\n&= \\ln(1 + e^x) - \\ln(1) \\\\\n&= \\ln(1 + e^x)\n\\end{align}\n\n\\textbf{(8)} \n\\begin{align}\nf(x) - f(-x) &= \\log(1 + e^x) - \\log(1 + e^{-x}) \\\\\n&= \\log(1 + e^x) - \\log\\left(\\frac{e^x + 1}{e^x}\\right) \\\\\n&= \\log(1 + e^x) - (\\log(e^x + 1) - x) \\\\\n&= x\n\\end{align}\n\n\\end{document}",
    "created_at": "2025-07-09T22:09:31.663088",
    "updated_at": "2025-07-09T22:09:31.663098"
  },
  {
    "id": "37ff5b44-c5df-4c16-895d-d69e70765733",
    "name": "Hw2",
    "filename": "Hw2.pdf",
    "latex_code": "\\documentclass{article}\n\\usepackage{amsmath, amssymb, amsfonts}\n\\usepackage{geometry}\n\\geometry{margin=1in}\n\n\\begin{document}\n\n\\section*{Homework 2}\n\n\\textbf{1)} Given:\n\\begin{align}\nP(A) &= 0.3 \\\\\nP(B) &= 0.4 \\\\\nP(A \\cap B) &= 0.2\n\\end{align}\n\n\\textbf{a)} \n\\begin{align}\nP(A \\cup B) &= P(A) + P(B) - P(A \\cap B) \\\\\n&= 0.3 + 0.4 - 0.2 \\\\\n&= 0.5\n\\end{align}\n\n\\textbf{b)} If $A$ and $B$ are independent:\n\\begin{align}\nP(A) \\cdot P(B) &= P(A \\cap B) \\\\\n0.3 \\cdot 0.4 &= 0.12 \\neq 0.2\n\\end{align}\nTherefore, $A$ and $B$ are not independent.\n\n\\textbf{c)} \n\\begin{align}\nP(A^c \\cap B) &= P(B) - P(A \\cap B) \\\\\n&= 0.4 - 0.2 \\\\\n&= 0.2\n\\end{align}\n\n\\textbf{2)} Given: $f_X(x) = \\begin{cases} 2x & 0 \\leq x \\leq 1 \\\\ 0 & \\text{otherwise} \\end{cases}$\n\n\\textbf{a)} \n\\begin{align}\nE(X) &= \\int_{-\\infty}^{\\infty} x f(x) dx \\\\\n&= \\int_0^1 x \\cdot 2x dx \\\\\n&= \\int_0^1 2x^2 dx \\\\\n&= \\frac{2x^3}{3}\\Big|_0^1 \\\\\n&= \\frac{2}{3}\n\\end{align}\n\n\\begin{align}\n\\text{Var}(X) &= E(X^2) - [E(X)]^2 \\\\\nE(X^2) &= \\int_{-\\infty}^{\\infty} x^2 f(x) dx \\\\\n&= \\int_0^1 x^2 \\cdot 2x dx \\\\\n&= \\int_0^1 2x^3 dx \\\\\n&= \\frac{2x^4}{4}\\Big|_0^1 \\\\\n&= \\frac{1}{2}\n\\end{align}\n\n\\begin{align}\n\\text{Var}(X) &= \\frac{1}{2} - \\left(\\frac{2}{3}\\right)^2 \\\\\n&= \\frac{1}{2} - \\frac{4}{9} \\\\\n&= \\frac{9-8}{18} \\\\\n&= \\frac{1}{18}\n\\end{align}\n\n\\textbf{b)} For Bernoulli distribution: $P(X = x) = p^x(1-p)^{1-x}$\n\n\\begin{align}\nP(X = 1) &= p^1(1-p)^0 = p \\\\\nP(X = 0) &= p^0(1-p)^1 = (1-p)\n\\end{align}\n\n\\begin{align}\nE(X) &= \\sum x P(X = x) \\\\\n&= 0(1-p) + 1(p) \\\\\n&= p\n\\end{align}\n\n\\begin{align}\nE(X^2) &= \\sum x^2 P(X = x) \\\\\n&= 0^2(1-p) + 1^2(p) \\\\\n&= p\n\\end{align}\n\n\\begin{align}\n\\text{Var}(X) &= E(X^2) - [E(X)]^2 \\\\\n&= p - p^2 \\\\\n&= p(1-p)\n\\end{align}\n\n\\newpage\n\n\\textbf{3)} Given: $f_{X,Y}(x,y) = 6xy$ for $0 \\leq x \\leq 1, 0 \\leq y \\leq 1$\n\n\\textbf{a)} \n\\begin{align}\nf_X(x) &= \\int_0^1 6xy dy \\\\\n&= 6x \\left[\\frac{y^2}{2}\\right]_0^1 \\\\\n&= 6x \\cdot \\frac{1}{2} \\\\\n&= 3x\n\\end{align}\n\nSimilarly:\n\\begin{align}\nf_Y(y) = 3y\n\\end{align}\n\n\\textbf{b)} \n\\begin{align}\nf_X(x) \\cdot f_Y(y) &= 3x \\cdot 3y = 9xy \\neq 6xy = f_{X,Y}(x,y)\n\\end{align}\nTherefore, $X$ and $Y$ are not independent.\n\n\\textbf{4)} Event $A$: sum is 5 or 6, so $P(A) = \\frac{9}{36} = \\frac{1}{4}$\n\nEvent $B$: at least one die shows 3, 4, 5, or 6\n\\begin{align}\n|B| &= \\{(3,6), (6,6), (3,6), (6,6), (6,3), (3,4), (6,3), (5,4), (4,5), (5,5)\\} \\\\\nP(B) &= \\frac{27}{36} = \\frac{3}{4}\n\\end{align}\n\n\\begin{align}\n|A \\cap B| &= \\{(3,3), (5,5), (5,6), (6,3), (6,5), (6,5)\\} \\\\\n&= 7 \\text{ outcomes} \\\\\nP(A \\cap B) &= \\frac{7}{36}\n\\end{align}\n\n\\begin{align}\nP(B|A) &= \\frac{P(A \\cap B)}{P(A)} \\\\\n&= \\frac{7/36}{1/4} \\\\\n&= \\frac{7}{36} \\cdot \\frac{4}{1} \\\\\n&= \\frac{7}{9}\n\\end{align}\n\n\\textbf{5)} Given: $f(x) = 3(1-x)^2$ and $Y = (1-X)^{1/3}$\n\nFrom $Y = (1-X)^{1/3}$:\n\\begin{align}\nY^{1/3} &= 1-X \\\\\nX &= 1-Y^{1/3}\n\\end{align}\n\n\\begin{align}\n\\frac{dx}{dy} &= -\\frac{1}{3}Y^{-2/3}\n\\end{align}\n\n\\begin{align}\nf_Y(y) &= f_X(1-y^{1/3}) \\left|\\frac{dx}{dy}\\right| \\\\\n&= 3(1-(1-y^{1/3}))^2 \\cdot \\frac{1}{3}y^{-2/3} \\\\\n&= 3(y^{1/3})^2 \\cdot \\frac{1}{3}y^{-2/3} \\\\\n&= 1\n\\end{align}\n\nTherefore: $f_Y(y) = \\begin{cases} 1 & 0 \\leq y \\leq 1 \\\\ 0 & \\text{otherwise} \\end{cases}$\n\n\\textbf{6)} For $\\text{Cov}\\left(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n a_j X_j\\right)$:\n\nLet $Y = \\sum_{i=1}^n a_i X_i$ and $Z = \\sum_{j=1}^n a_j X_j$\n\n\\begin{align}\nE(Y) &= E\\left(\\sum_{i=1}^n a_i X_i\\right) = \\sum_{i=1}^n a_i E(X_i) \\\\\nE(Z) &= \\sum_{j=1}^n a_j E(X_j)\n\\end{align}\n\n\\begin{align}\nE(YZ) &= E\\left(\\sum_{i=1}^n a_i X_i \\sum_{j=1}^n a_j X_j\\right) \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j E(X_i X_j)\n\\end{align}\n\n\\begin{align}\n\\text{Cov}(Y,Z) &= E(YZ) - E(Y)E(Z) \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j E(X_i X_j) - \\sum_{i=1}^n a_i E(X_i) \\sum_{j=1}^n a_j E(X_j) \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j [E(X_i X_j) - E(X_i)E(X_j)] \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j \\text{Cov}(X_i, X_j)\n\\end{align}\n\nSince $a^T \\Sigma a = \\sum_{i=1}^n \\sum_{j=1}^n a_i \\sigma_{ij} a_j = \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j \\text{Cov}(X_i, X_j)$\n\n\\newpage\n\n\\textbf{7)} Given: $f(x) = \\log(1 + e^x)$ and $\\sigma(x) = \\frac{e^x}{1 + e^x}$\n\n\\textbf{(1)} \n\\begin{align}\n\\frac{d f(x)}{dx} &= \\frac{1}{1 + e^x} \\cdot \\frac{d}{dx}(1 + e^x) \\\\\n&= \\frac{1}{1 + e^x} \\cdot e^x \\\\\n&= \\frac{e^x}{1 + e^x} \\\\\n&= \\sigma(x)\n\\end{align}\n\n\\textbf{(2)} \n\\begin{align}\n\\frac{d \\sigma(x)}{dx} &= \\frac{d}{dx}\\left(\\frac{e^x}{1 + e^x}\\right) \\\\\n&= \\frac{e^x(1 + e^x) - e^x \\cdot e^x}{(1 + e^x)^2} \\\\\n&= \\frac{e^x + e^{2x} - e^{2x}}{(1 + e^x)^2} \\\\\n&= \\frac{e^x}{(1 + e^x)^2} \\\\\n&= \\sigma(x) \\cdot \\frac{1}{1 + e^x} \\\\\n&= \\sigma(x)(1 - \\sigma(x))\n\\end{align}\n\n\\textbf{(3)} \n\\begin{align}\n\\log(\\sigma(x)) &= \\log\\left(\\frac{e^x}{1 + e^x}\\right) \\\\\n&= \\log(e^x) - \\log(1 + e^x) \\\\\n&= x - f(x)\n\\end{align}\n\n\\textbf{(4)} \n\\begin{align}\n1 - \\sigma(x) &= 1 - \\frac{e^x}{1 + e^x} \\\\\n&= \\frac{1 + e^x - e^x}{1 + e^x} \\\\\n&= \\frac{1}{1 + e^x}\n\\end{align}\n\nTherefore: $\\sigma(-x) = \\frac{e^{-x}}{1 + e^{-x}} = \\frac{1}{e^x + 1} = 1 - \\sigma(x)$\n\n\\textbf{(5)} \n\\begin{align}\n\\sigma^{-1}(x) &= \\log\\left(\\frac{x}{1-x}\\right)\n\\end{align}\n\nLet $y = \\sigma(x) = \\frac{e^x}{1 + e^x}$\n\nThen: $y(1 + e^x) = e^x$, so $y + ye^x = e^x$, which gives $y = e^x(1-y)$\n\nTherefore: $e^x = \\frac{y}{1-y}$, so $x = \\log\\left(\\frac{y}{1-y}\\right)$\n\n\\textbf{(6)} For $x > 0$:\n\\begin{align}\nf^{-1}(x) &= \\log(e^x - 1)\n\\end{align}\n\nLet $y = f(x) = \\log(1 + e^x)$\n\nThen: $e^y = 1 + e^x$, so $e^x = e^y - 1$\n\nTherefore: $x = \\log(e^y - 1)$\n\n\\textbf{(7)} \n\\begin{align}\nf(x) &= \\int_{-\\infty}^x \\sigma(y) dy \\\\\n&= \\int_{-\\infty}^x \\frac{e^y}{1 + e^y} dy\n\\end{align}\n\nLet $u = 1 + e^y$, then $du = e^y dy$:\n\\begin{align}\n\\int \\frac{e^y}{1 + e^y} dy &= \\int \\frac{1}{u} du \\\\\n&= \\ln(u) + C \\\\\n&= \\ln(1 + e^y) + C\n\\end{align}\n\n\\begin{align}\nf(x) &= \\ln(1 + e^x) - \\lim_{y \\to -\\infty} \\ln(1 + e^y) \\\\\n&= \\ln(1 + e^x) - \\ln(1) \\\\\n&= \\ln(1 + e^x)\n\\end{align}\n\n\\textbf{(8)} \n\\begin{align}\nf(x) - f(-x) &= \\log(1 + e^x) - \\log(1 + e^{-x}) \\\\\n&= \\log(1 + e^x) - \\log\\left(\\frac{e^x + 1}{e^x}\\right) \\\\\n&= \\log(1 + e^x) - [\\log(e^x + 1) - x] \\\\\n&= x\n\\end{align}\n\n\\end{document}",
    "created_at": "2025-07-09T22:19:10.219575",
    "updated_at": "2025-07-09T22:19:10.219609"
  },
  {
    "id": "b421080b-1ee5-4bf1-b790-f6656cd45156",
    "name": "Hw2",
    "filename": "Hw2.pdf",
    "latex_code": "\\documentclass{article}\n\\usepackage{amsmath, amssymb, amsfonts}\n\\usepackage{geometry}\n\\geometry{margin=1in}\n\n\\begin{document}\n\n\\section*{Homework 2}\n\n\\textbf{1)} Given:\n\\begin{align}\nP(A) &= 0.3 \\\\\nP(B) &= 0.4 \\\\\nP(A \\cap B) &= 0.2\n\\end{align}\n\n\\textbf{a)} \n\\begin{align}\nP(A \\cup B) &= P(A) + P(B) - P(A \\cap B) \\\\\n&= 0.3 + 0.4 - 0.2 \\\\\n&= 0.5\n\\end{align}\n\n\\textbf{b)} If $A$ and $B$ are independent:\n\\begin{align}\nP(A) \\cdot P(B) &= P(A \\cap B) \\\\\n0.3 \\cdot 0.4 &= 0.12 \\neq 0.2\n\\end{align}\nTherefore, $A$ and $B$ are not independent.\n\n\\textbf{c)} \n\\begin{align}\nP(A^c \\cap B) &= P(B) - P(A \\cap B) \\\\\n&= 0.4 - 0.2 \\\\\n&= 0.2\n\\end{align}\n\n\\textbf{2)} Given: $f_X(x) = \\begin{cases} 2x & 0 \\leq x \\leq 1 \\\\ 0 & \\text{otherwise} \\end{cases}$\n\n\\textbf{a)} \n\\begin{align}\nE(X) &= \\int_{-\\infty}^{\\infty} x f(x) \\, dx \\\\\n&= \\int_0^1 x \\cdot 2x \\, dx \\\\\n&= \\int_0^1 2x^2 \\, dx \\\\\n&= \\frac{2x^3}{3} \\Big|_0^1 \\\\\n&= \\frac{2}{3}\n\\end{align}\n\n\\begin{align}\n\\text{Var}(X) &= E(X^2) - [E(X)]^2 \\\\\nE(X^2) &= \\int_{-\\infty}^{\\infty} x^2 f(x) \\, dx \\\\\n&= \\int_0^1 x^2 \\cdot 2x \\, dx \\\\\n&= \\int_0^1 2x^3 \\, dx \\\\\n&= \\frac{2x^4}{4} \\Big|_0^1 \\\\\n&= \\frac{1}{2}\n\\end{align}\n\n\\begin{align}\n\\text{Var}(X) &= \\frac{1}{2} - \\left(\\frac{2}{3}\\right)^2 \\\\\n&= \\frac{1}{2} - \\frac{4}{9} \\\\\n&= \\frac{1}{18}\n\\end{align}\n\n\\textbf{b)} For a Bernoulli distribution: $P(X = x) = p^x(1-p)^{1-x}$\n\n\\begin{align}\nP(X = 1) &= p^1(1-p)^0 = p \\\\\nP(X = 0) &= p^0(1-p)^1 = (1-p)\n\\end{align}\n\n\\begin{align}\nE(X) &= \\sum x P(X = x) \\\\\n&= 0(1-p) + 1(p) \\\\\n&= p\n\\end{align}\n\n\\begin{align}\nE(X^2) &= \\sum x^2 P(X = x) \\\\\n&= 0^2(1-p) + 1^2(p) \\\\\n&= p\n\\end{align}\n\n\\begin{align}\n\\text{Var}(X) &= E(X^2) - [E(X)]^2 \\\\\n&= p - p^2 \\\\\n&= p(1-p)\n\\end{align}\n\n\\newpage\n\n\\textbf{3)} Given: $f_{X,Y}(x,y) = 6xy$ for $0 \\leq x \\leq 1, 0 \\leq y \\leq 1$\n\n\\textbf{a)} \n\\begin{align}\nf_X(x) &= \\int_0^1 6xy \\, dy \\\\\n&= 6x \\int_0^1 y \\, dy \\\\\n&= 6x \\cdot \\frac{y^2}{2} \\Big|_0^1 \\\\\n&= 6x \\cdot \\frac{1}{2} \\\\\n&= 3x\n\\end{align}\n\nSimilarly, $f_Y(y) = 3y$\n\n\\textbf{b)} \n\\begin{align}\nf_X(x) \\cdot f_Y(y) &= 3x \\cdot 3y = 9xy \\neq 6xy = f_{X,Y}(x,y)\n\\end{align}\nTherefore, $X$ and $Y$ are not independent.\n\n\\textbf{4)} Event $A$: sum is 5 or 6, so $P(A) = \\frac{9}{36} = \\frac{1}{4}$\n\nEvent $B$: outcomes $(3,6), (6,6), (3,6), (6,6), (6,3), (3,4), (6,3), (5,4), (4,5), (2,4)$\n$P(B) = \\frac{10}{36}$\n\n\\begin{align}\n|A \\cap B| &= |(5,4), (5,5), (5,6), (6,3), (6,4), (6,5), (4,6)| = 7 \\\\\nP(B|A) &= \\frac{P(A \\cap B)}{P(A)} = \\frac{7/36}{1/4} = \\frac{7/36}{9/36} = \\frac{7}{9}\n\\end{align}\n\n\\textbf{5)} Given: $f(x) = 3(1-x)^2$ and $Y = (1-X)^{1/3}$\n\nFrom $Y^{1/3} = 1-X$, we get $X = 1-Y^{1/3}$\n\n\\begin{align}\n\\frac{dx}{dy} &= -\\frac{1}{3}Y^{-2/3}\n\\end{align}\n\n\\begin{align}\nf_Y(y) &= f_X(1-y^{1/3}) \\left|\\frac{dx}{dy}\\right| \\\\\n&= 3(1-(1-y^{1/3}))^2 \\cdot \\frac{1}{3}y^{-2/3} \\\\\n&= 3(y^{1/3})^2 \\cdot \\frac{1}{3}y^{-2/3} \\\\\n&= 1\n\\end{align}\n\nTherefore, $f_Y(y) = 1$ for $0 \\leq y \\leq 1$, and 0 otherwise.\n\n\\textbf{6)} For $\\text{Cov}\\left(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n a_j X_j\\right)$:\n\nLet $Y = \\sum_{i=1}^n a_i X_i$ and $Z = \\sum_{j=1}^n a_j X_j$\n\n\\begin{align}\nE(Y) &= E\\left(\\sum_{i=1}^n a_i X_i\\right) = \\sum_{i=1}^n a_i E(X_i) \\\\\nE(Z) &= \\sum_{j=1}^n a_j E(X_j)\n\\end{align}\n\n\\begin{align}\nE(YZ) &= E\\left(\\sum_{i=1}^n a_i X_i \\sum_{j=1}^n a_j X_j\\right) \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j E(X_i X_j)\n\\end{align}\n\n\\begin{align}\n\\text{Cov}(Y,Z) &= E(YZ) - E(Y)E(Z) \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j E(X_i X_j) - \\sum_{i=1}^n a_i E(X_i) \\sum_{j=1}^n a_j E(X_j) \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j [E(X_i X_j) - E(X_i)E(X_j)] \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j \\text{Cov}(X_i, X_j)\n\\end{align}\n\nSince $a^T \\Sigma a = \\sum_{i=1}^n \\sum_{j=1}^n a_i \\Sigma_{ij} a_j = \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j \\text{Cov}(X_i, X_j)$\n\n\\newpage\n\n\\textbf{7)} Given: $f(x) = \\log(1 + e^x)$ and $\\sigma(x) = \\frac{e^x}{1 + e^x}$\n\n\\textbf{(1)} \n\\begin{align}\n\\frac{d f(x)}{dx} &= \\frac{1}{1 + e^x} \\cdot e^x = \\frac{e^x}{1 + e^x} = \\sigma(x)\n\\end{align}\n\n\\textbf{(2)} \n\\begin{align}\n\\frac{d \\sigma(x)}{dx} &= \\frac{d}{dx}\\left(\\frac{e^x}{1 + e^x}\\right) \\\\\n&= \\frac{e^x(1 + e^x) - e^x \\cdot e^x}{(1 + e^x)^2} \\\\\n&= \\frac{e^x + e^{2x} - e^{2x}}{(1 + e^x)^2} \\\\\n&= \\frac{e^x}{(1 + e^x)^2} \\\\\n&= \\frac{e^x}{1 + e^x} \\cdot \\frac{1}{1 + e^x} \\\\\n&= \\sigma(x)(1 - \\sigma(x))\n\\end{align}\n\n\\textbf{(3)} \n\\begin{align}\n\\log(\\sigma(x)) &= \\log\\left(\\frac{e^x}{1 + e^x}\\right) \\\\\n&= \\log(e^x) - \\log(1 + e^x) \\\\\n&= x - f(x)\n\\end{align}\n\n\\textbf{(4)} \n\\begin{align}\n1 - \\sigma(x) &= 1 - \\frac{e^x}{1 + e^x} = \\frac{1 + e^x - e^x}{1 + e^x} = \\frac{1}{1 + e^x}\n\\end{align}\n\nTherefore, $\\sigma(-x) = \\frac{e^{-x}}{1 + e^{-x}} = \\frac{1}{e^x + 1} = 1 - \\sigma(x)$\n\n\\textbf{(5)} \n\\begin{align}\n\\sigma^{-1}(x) &= \\log\\left(\\frac{x}{1-x}\\right)\n\\end{align}\n\nLet $y = \\sigma(x) = \\frac{e^x}{1 + e^x}$. Then:\n\\begin{align}\ny(1 + e^x) &= e^x \\\\\ny + ye^x &= e^x \\\\\ny &= e^x(1-y) \\\\\ne^x &= \\frac{y}{1-y} \\\\\nx &= \\log\\left(\\frac{y}{1-y}\\right)\n\\end{align}\n\n\\textbf{(6)} For $x \\to 0$: $f^{-1}(x) = \\log(e^x - 1)$\n\nLet $y = \\log(1 + e^x)$. Then:\n\\begin{align}\ne^y &= 1 + e^x \\\\\ne^x &= e^y - 1 \\\\\nx &= \\log(e^y - 1)\n\\end{align}\n\n\\textbf{(7)} \n\\begin{align}\nf(x) &= \\int_{-\\infty}^x \\sigma(y) \\, dy \\\\\n&= \\int_{-\\infty}^x \\frac{e^y}{1 + e^y} \\, dy\n\\end{align}\n\nLet $u = 1 + e^y$, then $du = e^y dy$:\n\\begin{align}\n\\int \\frac{e^y}{1 + e^y} \\, dy &= \\int \\frac{1}{u} \\, du = \\ln u = \\ln(1 + e^y)\n\\end{align}\n\n\\begin{align}\nf(x) &= \\ln(1 + e^x) \\Big|_{-\\infty}^x \\\\\n&= \\ln(1 + e^x) - \\ln(1 + e^{-\\infty}) \\\\\n&= \\ln(1 + e^x) - \\ln(1) \\\\\n&= \\ln(1 + e^x)\n\\end{align}\n\n\\textbf{(8)} \n\\begin{align}\nf(x) - f(-x) &= \\log(1 + e^x) - \\log(1 + e^{-x}) \\\\\n&= \\log(1 + e^x) - \\log\\left(\\frac{e^x + 1}{e^x}\\right) \\\\\n&= \\log(1 + e^x) - [\\log(e^x + 1) - x] \\\\\n&= x\n\\end{align}\n\n\\end{document}",
    "created_at": "2025-07-09T22:26:09.329763",
    "updated_at": "2025-07-09T22:26:09.329840"
  },
  {
    "id": "f620383d-d036-42cc-b4ae-f6c697cf8907",
    "name": "Hw2",
    "filename": "Hw2.pdf",
    "latex_code": "\\documentclass{article}\n\\usepackage{amsmath, amssymb, amsfonts}\n\\usepackage{geometry}\n\\geometry{margin=1in}\n\n\\begin{document}\n\n\\section*{Homework 2}\n\n\\textbf{1)} Given:\n\\begin{align}\nP(A) &= 0.3 \\\\\nP(B) &= 0.4 \\\\\nP(A \\cap B) &= 0.2\n\\end{align}\n\n\\textbf{a)} \n\\begin{align}\nP(A \\cup B) &= P(A) + P(B) - P(A \\cap B) \\\\\n&= 0.3 + 0.4 - 0.2 \\\\\n&= 0.5\n\\end{align}\n\n\\textbf{b)} If $A$ and $B$ are independent:\n\\begin{align}\nP(A) \\cdot P(B) &= P(A \\cap B) \\\\\n0.3 \\cdot 0.4 &= 0.12 \\neq 0.2\n\\end{align}\nTherefore, $A$ and $B$ are not independent.\n\n\\textbf{c)} \n\\begin{align}\nP(A^c \\cap B) &= P(B) - P(A \\cap B) \\\\\n&= 0.4 - 0.2 \\\\\n&= 0.2\n\\end{align}\n\n\\textbf{2)} Given: $f_X(x) = \\begin{cases} 2x & 0 \\leq x \\leq 1 \\\\ 0 & \\text{otherwise} \\end{cases}$\n\n\\textbf{a)} \n\\begin{align}\nE(X) &= \\int_{-\\infty}^{\\infty} x f(x) dx \\\\\n&= \\int_0^1 x \\cdot 2x dx \\\\\n&= \\int_0^1 2x^2 dx \\\\\n&= \\frac{2x^3}{3}\\Big|_0^1 \\\\\n&= \\frac{2}{3}\n\\end{align}\n\n\\begin{align}\n\\text{Var}(X) &= E(X^2) - [E(X)]^2 \\\\\nE(X^2) &= \\int_{-\\infty}^{\\infty} x^2 f(x) dx \\\\\n&= \\int_0^1 x^2 \\cdot 2x dx \\\\\n&= \\int_0^1 2x^3 dx \\\\\n&= \\frac{2x^4}{4}\\Big|_0^1 \\\\\n&= \\frac{1}{2}\n\\end{align}\n\n\\begin{align}\n\\text{Var}(X) &= \\frac{1}{2} - \\left(\\frac{2}{3}\\right)^2 \\\\\n&= \\frac{1}{2} - \\frac{4}{9} \\\\\n&= \\frac{9-8}{18} \\\\\n&= \\frac{1}{18}\n\\end{align}\n\n\\textbf{b)} For Bernoulli distribution: $P(X = x) = p^x(1-p)^{1-x}$\n\n\\begin{align}\nP(X = 1) &= p^1(1-p)^0 = p \\\\\nP(X = 0) &= p^0(1-p)^1 = (1-p)\n\\end{align}\n\n\\begin{align}\nE(X) &= \\sum x P(X = x) \\\\\n&= 0(1-p) + 1(p) \\\\\n&= p\n\\end{align}\n\n\\begin{align}\nE(X^2) &= \\sum x^2 P(X = x) \\\\\n&= 0^2(1-p) + 1^2(p) \\\\\n&= p\n\\end{align}\n\n\\begin{align}\n\\text{Var}(X) &= E(X^2) - [E(X)]^2 \\\\\n&= p - p^2 \\\\\n&= p(1-p)\n\\end{align}\n\n\\newpage\n\n\\textbf{3)} Given: $f_{X,Y}(x,y) = 6xy$ for $0 \\leq x \\leq 1, 0 \\leq y \\leq 1$\n\n\\textbf{a)} \n\\begin{align}\nf_X(x) &= \\int_0^1 6xy dy \\\\\n&= 6x \\left[\\frac{y^2}{2}\\right]_0^1 \\\\\n&= 6x \\cdot \\frac{1}{2} \\\\\n&= 3x\n\\end{align}\n\nSimilarly:\n\\begin{align}\nf_Y(y) = 3y\n\\end{align}\n\n\\textbf{b)} \n\\begin{align}\nf_X(x) \\cdot f_Y(y) &= 3x \\cdot 3y = 9xy \\neq 6xy = f_{X,Y}(x,y)\n\\end{align}\nTherefore, $X$ and $Y$ are not independent.\n\n\\textbf{4)} Event $A$: sum is 5 or 6, so $P(A) = \\frac{9}{36} = \\frac{1}{4}$\n\nEvent $B$: at least one die shows 3, 4, 5, or 6\n\\begin{align}\n|B| &= \\{(3,6), (4,6), (5,6), (6,6), (6,3), (6,4), (6,5), (3,4), (4,3), (5,4), (4,5)\\} \\\\\nP(B) &= \\frac{10}{36}\n\\end{align}\n\n\\begin{align}\nP(B|A) &= \\frac{P(A \\cap B)}{P(A)}\n\\end{align}\n\n\\begin{align}\n|A \\cap B| &= \\{(5,4), (5,5), (5,6), (6,3), (6,4), (6,5), (4,5)\\} \\\\\n&= 7\n\\end{align}\n\n\\begin{align}\nP(B|A) &= \\frac{7/36}{1/4} = \\frac{7/36}{9/36} = \\frac{7}{9}\n\\end{align}\n\n\\textbf{5)} Given: $f(x) = 3(1-x)^2$ for $0 \\leq x \\leq 1$\n\nLet $Y = (1-X)^{1/3}$, so $Y^{1/3} = 1-X$, which gives $X = 1-Y^{1/3}$\n\n\\begin{align}\n\\frac{dx}{dy} &= -\\frac{1}{3}Y^{-2/3}\n\\end{align}\n\n\\begin{align}\nf_Y(y) &= f_X(1-y^{1/3}) \\left|\\frac{dx}{dy}\\right| \\\\\n&= 3(1-(1-y^{1/3}))^2 \\cdot \\frac{1}{3}y^{-2/3} \\\\\n&= 3(y^{1/3})^2 \\cdot \\frac{1}{3}y^{-2/3} \\\\\n&= 1\n\\end{align}\n\nTherefore: $f_Y(y) = \\begin{cases} 1 & 0 \\leq y \\leq 1 \\\\ 0 & \\text{otherwise} \\end{cases}$\n\n\\textbf{6)} For $\\text{Cov}\\left(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n a_j X_j\\right)$:\n\n\\begin{align}\nY &= \\sum_{i=1}^n a_i X_i, \\quad Z = \\sum_{j=1}^n a_j X_j\n\\end{align}\n\n\\begin{align}\nE(Y) &= E\\left(\\sum_{i=1}^n a_i X_i\\right) = \\sum_{i=1}^n a_i E(X_i) \\\\\nE(Z) &= \\sum_{j=1}^n a_j E(X_j)\n\\end{align}\n\n\\begin{align}\nE(YZ) &= E\\left(\\sum_{i=1}^n a_i X_i \\sum_{j=1}^n a_j X_j\\right) \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j E(X_i X_j)\n\\end{align}\n\n\\begin{align}\n\\text{Cov}(Y,Z) &= E(YZ) - E(Y)E(Z) \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j E(X_i X_j) - \\sum_{i=1}^n a_i E(X_i) \\sum_{j=1}^n a_j E(X_j) \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j [E(X_i X_j) - E(X_i)E(X_j)] \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j \\text{Cov}(X_i, X_j)\n\\end{align}\n\nSince $a^T S a = \\sum_{i=1}^n \\sum_{j=1}^n a_i S_{ij} a_j = \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j \\text{Cov}(X_i, X_j)$\n\n\\newpage\n\n\\textbf{7)} Given: $f(x) = \\log(1 + e^x)$ and $\\sigma(x) = \\frac{e^x}{1 + e^x}$\n\n\\textbf{(1)} \n\\begin{align}\n\\frac{d f(x)}{dx} &= \\frac{1}{1 + e^x} \\cdot e^x = \\frac{e^x}{1 + e^x} = \\sigma(x)\n\\end{align}\n\n\\textbf{(2)} \n\\begin{align}\n\\frac{d \\sigma(x)}{dx} &= \\frac{d}{dx}\\left(\\frac{e^x}{1 + e^x}\\right) \\\\\n&= \\frac{e^x(1 + e^x) - e^x \\cdot e^x}{(1 + e^x)^2} \\\\\n&= \\frac{e^x + e^{2x} - e^{2x}}{(1 + e^x)^2} \\\\\n&= \\frac{e^x}{(1 + e^x)^2} \\\\\n&= \\sigma(x) \\cdot \\frac{1}{1 + e^x} \\\\\n&= \\sigma(x)(1 - \\sigma(x))\n\\end{align}\n\n\\textbf{(3)} \n\\begin{align}\n\\log(\\sigma(x)) &= \\log\\left(\\frac{e^x}{1 + e^x}\\right) \\\\\n&= \\log(e^x) - \\log(1 + e^x) \\\\\n&= x - f(x) \\\\\n&= -f(-x)\n\\end{align}\n\n\\textbf{(4)} \n\\begin{align}\n1 - \\sigma(x) &= 1 - \\frac{e^x}{1 + e^x} \\\\\n&= \\frac{1 + e^x - e^x}{1 + e^x} \\\\\n&= \\frac{1}{1 + e^x} \\\\\n&= \\frac{e^{-x}}{e^{-x}(1 + e^x)} \\\\\n&= \\frac{e^{-x}}{e^{-x} + 1} \\\\\n&= \\sigma(-x)\n\\end{align}\n\n\\textbf{(5)} \n\\begin{align}\n\\sigma^{-1}(x) &= \\log\\left(\\frac{x}{1-x}\\right)\n\\end{align}\n\nLet $y = \\sigma(x) = \\frac{e^x}{1 + e^x}$\n\nThen: $y(1 + e^x) = e^x$, so $y + ye^x = e^x$, which gives $y = e^x(1-y)$\n\nTherefore: $e^x = \\frac{y}{1-y}$, and $x = \\log\\left(\\frac{y}{1-y}\\right)$\n\n\\textbf{(6)} For $x > 0$:\n\\begin{align}\nf^{-1}(x) &= \\log(e^x - 1)\n\\end{align}\n\nLet $y = \\log(1 + e^x)$. Then $e^y = 1 + e^x$, so $e^x = e^y - 1$, and $x = \\log(e^y - 1)$.\n\n\\textbf{(7)} \n\\begin{align}\nf(x) &= \\int_{-\\infty}^x \\sigma(y) dy \\\\\n&= \\int_{-\\infty}^x \\frac{e^y}{1 + e^y} dy\n\\end{align}\n\nLet $u = 1 + e^y$, then $du = e^y dy$:\n\\begin{align}\n\\int \\frac{1}{u} du &= \\ln(1 + e^y)\\Big|_{-\\infty}^x \\\\\n&= \\ln(1 + e^x) - \\ln(1 + e^{-\\infty}) \\\\\n&= \\ln(1 + e^x) - \\ln(1) \\\\\n&= \\ln(1 + e^x)\n\\end{align}\n\n\\textbf{(8)} \n\\begin{align}\nf(x) - f(-x) &= \\log(1 + e^x) - \\log(1 + e^{-x}) \\\\\n&= \\log(1 + e^x) - \\log\\left(\\frac{e^x + 1}{e^x}\\right) \\\\\n&= \\log(1 + e^x) - [\\log(e^x + 1) - x] \\\\\n&= x\n\\end{align}\n\n\\end{document}",
    "created_at": "2025-07-09T22:27:08.560134",
    "updated_at": "2025-07-09T22:27:08.560143"
  },
  {
    "id": "bf3721e3-f039-44ac-8c81-842ae5ea7cad",
    "name": "Hw2",
    "filename": "Hw2.pdf",
    "original_pdf_path": "uploads/Hw2.pdf",
    "latex_code": "\\documentclass{article}\n\\usepackage{amsmath, amssymb, amsfonts}\n\\usepackage{geometry}\n\\geometry{margin=1in}\n\n\\begin{document}\n\n\\section*{Homework 2}\n\n\\textbf{1)} Given:\n\\begin{align}\nP(A) &= 0.3 \\\\\nP(B) &= 0.4 \\\\\nP(A \\cap B) &= 0.2\n\\end{align}\n\n\\textbf{a)} \n\\begin{align}\nP(A \\cup B) &= P(A) + P(B) - P(A \\cap B) \\\\\n&= 0.3 + 0.4 - 0.2 \\\\\n&= 0.5\n\\end{align}\n\n\\textbf{b)} If $A$ and $B$ are independent:\n\\begin{align}\nP(A) \\cdot P(B) &= P(A \\cap B) \\\\\n0.3 \\cdot 0.4 &= 0.12 \\neq 0.2\n\\end{align}\nTherefore, $A$ and $B$ are not independent.\n\n\\textbf{c)} \n\\begin{align}\nP(A^c \\cap B) &= P(B) - P(A \\cap B) \\\\\n&= 0.4 - 0.2 \\\\\n&= 0.2\n\\end{align}\n\n\\textbf{2)} Given: $f_X(x) = \\begin{cases} 2x & 0 \\leq x \\leq 1 \\\\ 0 & \\text{otherwise} \\end{cases}$\n\n\\textbf{a)} \n\\begin{align}\nE(X) &= \\int_{-\\infty}^{\\infty} x f(x) dx \\\\\n&= \\int_0^1 x \\cdot 2x dx \\\\\n&= \\int_0^1 2x^2 dx \\\\\n&= \\frac{2x^3}{3}\\Big|_0^1 \\\\\n&= \\frac{2}{3}\n\\end{align}\n\n\\begin{align}\n\\text{Var}(X) &= E(X^2) - [E(X)]^2 \\\\\nE(X^2) &= \\int_{-\\infty}^{\\infty} x^2 f(x) dx \\\\\n&= \\int_0^1 x^2 \\cdot 2x dx \\\\\n&= \\int_0^1 2x^3 dx \\\\\n&= \\frac{2x^4}{4}\\Big|_0^1 \\\\\n&= \\frac{1}{2}\n\\end{align}\n\n\\begin{align}\n\\text{Var}(X) &= \\frac{1}{2} - \\left(\\frac{2}{3}\\right)^2 \\\\\n&= \\frac{1}{2} - \\frac{4}{9} \\\\\n&= \\frac{9-8}{18} \\\\\n&= \\frac{1}{18}\n\\end{align}\n\n\\textbf{b)} For $P(X = x) = p^x(1-p)^{1-x}$ where $x \\in \\{0,1\\}$:\n\n\\begin{align}\nP(X = 1) &= p^1(1-p)^0 = p \\\\\nP(X = 0) &= p^0(1-p)^1 = (1-p)\n\\end{align}\n\n\\begin{align}\nE(X) &= \\sum x P(X = x) \\\\\n&= 0(1-p) + 1(p) \\\\\n&= p\n\\end{align}\n\n\\begin{align}\nE(X^2) &= \\sum x^2 P(X = x) \\\\\n&= 0^2(1-p) + 1^2(p) \\\\\n&= p\n\\end{align}\n\n\\begin{align}\n\\text{Var}(X) &= E(X^2) - [E(X)]^2 \\\\\n&= p - p^2 \\\\\n&= p(1-p)\n\\end{align}\n\n\\newpage\n\n\\textbf{3)} Given: $f_{X,Y}(x,y) = 6xy$ for $0 \\leq x \\leq 1, 0 \\leq y \\leq 1$\n\n\\textbf{a)} \n\\begin{align}\nf_X(x) &= \\int_0^1 6xy dy \\\\\n&= 6x \\int_0^1 y dy \\\\\n&= 6x \\cdot \\frac{y^2}{2}\\Big|_0^1 \\\\\n&= 6x \\cdot \\frac{1}{2} \\\\\n&= 3x\n\\end{align}\n\nSimilarly, $f_Y(y) = 3y$\n\n\\textbf{b)} \n\\begin{align}\nf_X(x) \\cdot f_Y(y) &= 3x \\cdot 3y = 9xy \\neq 6xy = f_{X,Y}(x,y)\n\\end{align}\nTherefore, $X$ and $Y$ are not independent.\n\n\\textbf{4)} Rolling two dice:\n\nEvent $A$: sum is 5 or 6\nEvent $B$: at least one die shows 5 or 6\n\n\\begin{align}\n|A| &= |\\{(1,4), (2,3), (3,2), (4,1), (1,5), (2,4), (3,3), (4,2), (5,1), (6,0)\\}| \\\\\n&= 7 \\text{ (valid outcomes)} \\\\\nP(A) &= \\frac{7}{36}\n\\end{align}\n\n\\begin{align}\n|B| &= |\\{(1,5), (1,6), (2,5), (2,6), (3,5), (3,6), (4,5), (4,6), (5,1), (5,2), (5,3), (5,4), (5,5), (5,6), (6,1), (6,2), (6,3), (6,4), (6,5), (6,6)\\}| \\\\\n&= 20 \\\\\nP(B) &= \\frac{20}{36} = \\frac{5}{9}\n\\end{align}\n\n\\begin{align}\n|A \\cap B| &= |\\{(1,5), (5,1), (2,4), (4,2), (3,3), (1,6), (6,0)\\}| \\\\\n&= 7 \\text{ (but }(6,0)\\text{ is invalid, so 6 valid)} \\\\\nP(B|A) &= \\frac{P(A \\cap B)}{P(A)} = \\frac{6/36}{7/36} = \\frac{6}{7}\n\\end{align}\n\n\\textbf{5)} Given: $f(x) = 3(1-x)^2$ and $Y = (1-X)^{1/3}$\n\nFrom $Y = (1-X)^{1/3}$, we get $Y^3 = 1-X$, so $X = 1-Y^3$\n\n\\begin{align}\n\\frac{dx}{dy} &= -3Y^2\n\\end{align}\n\n\\begin{align}\nf_Y(y) &= f_X(1-y^3) \\left|\\frac{dx}{dy}\\right| \\\\\n&= 3(1-(1-y^3))^2 \\cdot 3y^2 \\\\\n&= 3(y^3)^2 \\cdot 3y^2 \\\\\n&= 9y^8\n\\end{align}\n\nTherefore, $f_Y(y) = \\begin{cases} 9y^8 & 0 \\leq y \\leq 1 \\\\ 0 & \\text{otherwise} \\end{cases}$\n\n\\textbf{6)} For $\\text{Cov}\\left(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n a_j X_j\\right)$:\n\nLet $Y = \\sum_{i=1}^n a_i X_i$ and $Z = \\sum_{j=1}^n a_j X_j$\n\n\\begin{align}\nE(Y) &= E\\left(\\sum_{i=1}^n a_i X_i\\right) = \\sum_{i=1}^n a_i E(X_i) \\\\\nE(Z) &= \\sum_{j=1}^n a_j E(X_j)\n\\end{align}\n\n\\begin{align}\nE(YZ) &= E\\left(\\sum_{i=1}^n a_i X_i \\sum_{j=1}^n a_j X_j\\right) \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j E(X_i X_j)\n\\end{align}\n\n\\begin{align}\n\\text{Cov}(Y,Z) &= E(YZ) - E(Y)E(Z) \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j E(X_i X_j) - \\sum_{i=1}^n a_i E(X_i) \\sum_{j=1}^n a_j E(X_j) \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j [E(X_i X_j) - E(X_i)E(X_j)] \\\\\n&= \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j \\text{Cov}(X_i, X_j)\n\\end{align}\n\nSince $a^T \\Sigma a = \\sum_{i=1}^n \\sum_{j=1}^n a_i \\sigma_{ij} a_j = \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j \\text{Cov}(X_i, X_j)$\n\n\\newpage\n\n\\textbf{7)} Given: $f(x) = \\log(1 + e^x)$ and $\\sigma(x) = \\frac{e^x}{1 + e^x}$\n\n\\textbf{(1)} \n\\begin{align}\n\\frac{d f(x)}{dx} &= \\frac{1}{1 + e^x} \\cdot \\frac{d}{dx}(1 + e^x) \\\\\n&= \\frac{1}{1 + e^x} \\cdot e^x \\\\\n&= \\frac{e^x}{1 + e^x} \\\\\n&= \\sigma(x)\n\\end{align}\n\n\\textbf{(2)} \n\\begin{align}\n\\frac{d \\sigma(x)}{dx} &= \\frac{d}{dx}\\left(\\frac{e^x}{1 + e^x}\\right) \\\\\n&= \\frac{e^x(1 + e^x) - e^x \\cdot e^x}{(1 + e^x)^2} \\\\\n&= \\frac{e^x + e^{2x} - e^{2x}}{(1 + e^x)^2} \\\\\n&= \\frac{e^x}{(1 + e^x)^2} \\\\\n&= \\frac{e^x}{1 + e^x} \\cdot \\frac{1}{1 + e^x} \\\\\n&= \\sigma(x)(1 - \\sigma(x))\n\\end{align}\n\n\\textbf{(3)} \n\\begin{align}\n\\log(\\sigma(x)) &= \\log\\left(\\frac{e^x}{1 + e^x}\\right) \\\\\n&= \\log(e^x) - \\log(1 + e^x) \\\\\n&= x - \\log(1 + e^x) \\\\\n&= x - f(x) \\\\\n&= -f(-x)\n\\end{align}\n\n\\textbf{(4)} \n\\begin{align}\n1 - \\sigma(x) &= 1 - \\frac{e^x}{1 + e^x} \\\\\n&= \\frac{1 + e^x - e^x}{1 + e^x} \\\\\n&= \\frac{1}{1 + e^x} \\\\\n&= \\frac{e^{-x}}{e^{-x}(1 + e^x)} \\\\\n&= \\frac{e^{-x}}{e^{-x} + 1} \\\\\n&= \\sigma(-x)\n\\end{align}\n\n\\textbf{(5)} \n\\begin{align}\n\\sigma^{-1}(x) &= \\log\\left(\\frac{x}{1-x}\\right)\n\\end{align}\n\nLet $y = \\sigma(x) = \\frac{e^x}{1 + e^x}$\n\nThen $y(1 + e^x) = e^x$, so $y + ye^x = e^x$, which gives $y = e^x(1-y)$\n\nTherefore $e^x = \\frac{y}{1-y}$, and $x = \\log\\left(\\frac{y}{1-y}\\right)$\n\n\\textbf{(6)} For $x > 0$, $f^{-1}(x) = \\log(e^x - 1)$\n\nLet $y = f(x) = \\log(1 + e^x)$\n\nThen $e^y = 1 + e^x$, so $e^x = e^y - 1$, and $x = \\log(e^y - 1)$\n\n\\textbf{(7)} \n\\begin{align}\nf(x) &= \\int_{-\\infty}^x \\sigma(y) dy \\\\\n&= \\int_{-\\infty}^x \\frac{e^y}{1 + e^y} dy\n\\end{align}\n\nLet $u = 1 + e^y$, then $du = e^y dy$\n\n\\begin{align}\n\\int \\frac{e^y}{1 + e^y} dy &= \\int \\frac{1}{u} du \\\\\n&= \\ln(u) + C \\\\\n&= \\ln(1 + e^y) + C \\\\\n&= \\log(1 + e^y) + C\n\\end{align}\n\n\\begin{align}\nf(x) &= \\lim_{a \\to -\\infty} [\\log(1 + e^x) - \\log(1 + e^a)] \\\\\n&= \\log(1 + e^x) - \\log(1) \\\\\n&= \\log(1 + e^x)\n\\end{align}\n\n\\textbf{(8)} \n\\begin{align}\nf(x) - f(-x) &= \\log(1 + e^x) - \\log(1 + e^{-x}) \\\\\n&= \\log(1 + e^x) - \\log\\left(\\frac{e^x + 1}{e^x}\\right) \\\\\n&= \\log(1 + e^x) - [\\log(e^x + 1) - x] \\\\\n&= x\n\\end{align}\n\n\\end{document}",
    "created_at": "2025-07-09T22:33:07.833181",
    "updated_at": "2025-07-09T22:33:07.833210"
  }
]